\chapter{Revisão Bibliográfica} \label{chap:sota}

\section{Introdução}

Neste capítulo são analisadas todas as áreas científicas relevantes para que esta dissertação possa ser realizada com sucesso, tirando partido do conhecimento mais avançado do que está a ser feito a nível mundial e até equacionar novas abordagens para melhorar as soluções existentes para o problema do reconhecimento de objetos. Mais particularmente será analisado o que está feito em termos de reconhecimento de objetos 3D tanto na vertente científica como das bibliotecas informáticas existentes nesse âmbito.

Faz-se também uma análise ao que existe em termos de demonstradores de robótica autónoma para enquadrar o trabalho a ser desenvolvido respeitante à identificação dos objetos, que sendo reconhecidos, influenciam o comportamento do robô.

\section{Sensores de Profundidade}

\subsection{Time of Flight Camera}

Esta câmara tem recetores para obter o tempo de voo (i.e.: time-of-flight)
de uma partícula de luz de modo a saber a que distância se encontram os
obstáculos no campo de visão da câmara. Existem várias implementações desta
tecnologia, mas a mais usual é ter um emissor de luz, por norma um laser,
que envia pulsos de luz que são refletidos nos obstáculos e são captados por
um sensor que a cada “pixel” recebe a distância a que o objeto se encontra.

É um sensor que tem muitas aplicações, entre as quais a deteção de objetos nas imediações pois permite obter distâncias dos objetos que se encontram no seu campo de visão sem que isso implique um maior custo de cálculo através de algoritmos de visão por computador. 

\subsection[LIDAR]{Light Detection and Ranging}

Os sistemas LIDAR (\emph{Light Detection and Ranging}) utilizam um feixe de luz rotativo para fazer mapeamento 3D
do ambiente que o circunda. A vantagem destes sistemas é que, com feixes de luz muito estreitos conseguem obter uma resolução muito grande, sendo o ideal para aplicações críticas, tais como o alunar de sondas no caso da NASA \cite{Keim2010}.

Os LIDAR utilizam técnicas de \emph{backscattering} para conseguir uma medição
precisa de distância (além de algumas características do alvo), sendo necessário fazer algumas considerações prévias sobre o meio em que se vai propagar o laser para escolher o melhor comprimento de onda.


\subsection{Kinect}\label{kinect}

O \emph{Kinect} é um sensor 3D desenvolvido pela \emph{Microsoft}, cujo objetivo principal era ser utilizado a par com o sistema \emph{X-Box 360}, para a interação com jogos sem recorrer a controladores, sendo que através deste sensor os movimentos do jogador controlam o jogo. Este foi o primeiro sensor 3D disponível para o utilizador comum e permitiu a massificação do acesso da comunidade cientifica a este tipo de sensores, que de outra forma seriam demasiado dispendiosos.

As aplicações deste sensor fora do âmbito original para que foi desenvolvido são inúmeras, e rapidamente foi desenvolvido um controlador \emph{opensource} para se desenvolver aplicações em qualquer sistema operativo.

\begin{center}
	\includegraphics[width=0.80\textwidth]{./figures/Kinect.png}
	\captionof{figure}{Composição do Kinect \cite{wiredkinect}}
	\label{fig:5}
\end{center}

O \emph{Kinect} tem, como se pode ver na figura~\ref{fig:5}, uma câmara normal RGB 
contudo o sensor que extrai a perceção de profundidade é a câmara de infra-vermelhos à direita
que capta os infra-vermelhos enviados pelo emissor situado à esquerda.

Entretanto foi lançado no \emph{Windows SDK} um controlador e uma \emph{framework} oficiais para se desenvolver aplicações fazendo uso do \emph{Kinect} na plataforma \emph{Windows}.


\section{Técnicas de Reconhecimento de Objetos}\label{objdetect}

Nesta secção do documento apresenta-se e explora-se as técnicas mais promissoras de deteção e reconhecimento de objetos em imagens 2D e
em estruturas de representação em 3D que assumem a maior importância no âmbito do ramo científico da visão por computador.

\subsection[SIFT]{Scale Invariant Feature Transform}\label{sift}

\emph{Scale-Invariant Feature Transform} (SIFT) \cite{Lowe:1999:ORL:850924.851523} é uma técnica para o reconhecimento de objetos bastante popular em computação visual. Para fazer o reconhecimento de objetos, esta técnica necessita de um treino prévio, onde são extraídas características que não variam com a escala, rotações nem com projeções em 3D, sendo também parcialmente resistente a diferenças em iluminação.

A qualidade desta técnica está dependente da qualidade das características que extrai, e do facto de estas serem invariantes apesar das transformações que se possa aplicar à imagem.

A extração de características é feita em vários passos. O primeiro é a aplicação da função gaussiana na direção horizontal a todas as linhas de pixeis e de seguida na vertical em todas as colunas.
É utilizada também uma pirâmide de imagens onde se fez uma progressiva interpolação bilinear para suavizar a imagem, sendo que  a função gaussiana é aplicada a todas as camadas de modo a que cada uma seja comparada às suas adjacentes para determinar os máximos e os mínimos.

\begin{equation}
g(x) = \frac{1}{\sqrt{2\pi\sigma}}e^{-x^3 / 2 \sigma^2}
\end{equation}

O resultado desta análise é um conjunto de vetores que representam as características do objeto.


\begin{center}
	\includegraphics[scale=1.00]{figures/sift_img.png}
	\captionof{figure}{Exemplo de Deteção utilizando SIFT \cite{Lowe:1999:ORL:850924.851523}}
	\label{fig:sift}
\end{center}

\subsection[SURF]{Speeded Up Robust Feature}

Speeded Up Robust Feature (SURF) é uma técnica bastante próxima de SIFT\ref{sift}, contudo tem a vantagem de ser mais robusta às transformações que se pode fazer às imagens conseguindo também, ao mesmo tempo, aumentar a performance e a repetibilidade da deteção nas imagens \cite{citeulike:973069}.

As melhorias enunciadas são conseguidas através da escolha cuidadosa dos pontos característicos de um objeto. Esta escolha é feita utilizando o conceito de imagens integrais \cite{10.1109CVPR.2001.990517} cujo conceito básico é que cada pixel $x$ na imagem inicial é a soma dos valores dos pixeis no retângulo formado pela origem da imagem e as coordenadas do pixel atual:

\begin{equation}
I_\sum(x) = \sum_{i \leq x}^{i=0} \sum_{j \leq y}^{j=0} I(i,j)
\end{equation}


A vantagem destas imagens integrais é que são necessárias apenas adições para calcular a soma das intensidades em qualquer área retangular vertical.

Os pontos característicos são encontrados onde o determinante de uma matriz hessiana é máxima.


\subsection{Geometric Hashing}

O \emph{geometric hashing}, tal como os métodos acima representados é uma técnica baseada em modelos pré-existentes que visa reconhecer objetos onde são aplicadas rotações, translações e escala \cite{1989SPIE.1095..515C}.

Esta técnica tem por base também pontos característicos que são obtidos por conjuntos de três pontos não colineares segundo os quais os outros são achados. 
Desta forma os seus pontos característicos não variam de acordo com as transformações que possam ser aplicadas aos objetos.

%\subsection{Conditional Random Fields}

\subsection{RANSAC}

RANSAC\cite{Fischler:1981:RSC:358669.358692}, um acrónimo de \emph{RANdom SAmple Consensus}, é um algoritmo que permite extrair, através de um conjunto de dados, os parâmetros do modelo matemático que compõe as características aproximadas do objeto. Este algoritmo funciona de forma iterativa, sendo que a cada iteração melhora a qualidade dos parâmetros extraídos.

Este método representa uma evolução significativa dos métodos mínimos quadrados visto ser permeável a desvio dos dados sem que estes afetem a qualidade da modelação matemática.
Como se pode ver na figura \ref{fig:ransac_vs_lsq} o método \emph{RANSAC} será um método melhor para uma situação real onde os dados têm muito ruído.


\begin{center}
	\includegraphics[width=0.80\textwidth]{figures/least_squares_vs_ransac.png}
	\captionof{figure}{Comparação com o método de mínimos quadrados \cite{Fischler:1981:RSC:358669.358692}}
	\label{fig:ransac_vs_lsq}
\end{center}



\begin{center}
	\includegraphics[width=0.80\textwidth]{figures/least_squares_shortcomings.png}
	\captionof{figure}{Exemplo de fraqueza do método de mínimos quadrados \cite{Fischler:1981:RSC:358669.358692}}
	\label{fig:ransac}
\end{center}


\subsection[PCL]{Point Cloud Library}

\emph{Point Cloud Library} (PCL) é um projeto \emph{opensource} desenvolvido em C++ cujo objetivo é disponibilizar uma ferramenta altamente otimizada para capturar, manipular, visualizar e processar nuvens de pontos. Nuvens de pontos são a informação 3D que sensores como o \emph{Kinect} (\ref{kinect}) devolvem, que não é mais do que a nuvem dos pontos captados no espaço, com a origem no ponto onde o sensor se encontra, também com a informação das cores dos pontos.
O projeto PCL \cite{Rusu_ICRA2011_PCL} permite que através da nuvem de pontos se extraia a informação desejada, sendo que já tem implementado um conjunto de filtros, técnicas de reconstrução de superfícies, métodos de extração de características 3D (por exemplo normais às superfícies), que a tornam uma ferramenta de muito interessante para usar a par do \emph{Kinect}.

A captura de imagens é bastante facilitada com esta ferramenta, que disponibiliza um formato para que toda a informação seja guardada convenientemente: \emph{.pcd}. Estes ficheiros podem ser visualizados facilmente recorrendo a bibliotecas de visualização da PCL onde são apresentados em 3D, sendo que podem conter só informação de profundidade como na figura~\ref{fig:pcl_depth}, mas também com toda a informação capturada pelo \emph{Kinect} como pode ser visto na figura~\ref{fig:pcl_color}.

\begin{center}
	\includegraphics[width=0.80\textwidth]{figures/pcl_openni.png}
	\captionof{figure}{Exemplo de imagem capturada só com a informação de profundidade}
	\label{fig:pcl_depth}
	
\end{center}

\begin{center}
	\includegraphics[width=0.80\textwidth]{figures/pcl_color.png}
	\captionof{figure}{Exemplo de imagem capturada com informação RGBD}
	\label{fig:pcl_color}
	
\end{center}


\section{Algoritmos de Clustering}~\label{sec:clustering}

Tendo-se já explorado algoritmos de identificação de objetos e os sensores, é conveniente também uma abordagem aos algoritmos de \emph{clustering}, isto porque numa dada imagem em 3D, o que existe são uma série de pontos distribuídos no espaço com a informação de cor, sendo então necessário distinguir quais pertencem a um dado objeto e não a outro.

As técnicas de \emph{clustering} permite que se distribua os pontos por uma série de grupos de acordo com uma série de características dos mesmo e de algumas pré-condições fornecidas.

São expostas nesta secção algumas técnicas de \emph{clustering}, nomeadamente as que apresentam mais vantagens e conveniência para esta dissertação.

\subsection{Clustering por Vizinhança Euclideana}

Este algoritmo simples implica que seja fornecido um número mínimo de pontos e uma distância máxima para que seja definida uma vizinhança e daí a pertença ou não a um \emph{cluster}. A simplicidade deste algoritmo permite que seja facilmente implementado, contudo é muito sensível aos parâmetros iniciais.
Esta técnica aliada a uma pré-organização dos pontos, como, por exemplo, numa árvore binária do tipo k-d tree\cite{Bentley:1975:MBS:361002.361007} é um algoritmo de \emph{clustering} facilita ainda mais o processo de \emph{clusterização}.


\section{Demonstradores de Robótica Autónoma}
Esta secção refere-se a demonstradores de robótica autónoma, onde são referidos
os exemplos que traduzem o que se está a fazer no âmbito de demonstradores de
robótica autónoma e que representam o estado da arte nesta área.


\subsection{DARPA: Grand Challenge}
A agência norte americana DARPA (\emph{Defense Advanced Research Agency}), cujos projetos de investigação se destinam principalmente a aplicações militares, realizou três grandes eventos onde foram postos à prova as técnicas de condução autónoma de veículos comerciais devidamente equipados e modificados para se poderem mover de uma forma completamente autónoma.  

Existiram duas edições do \emph{Grand Challenge} realizadas em 2004 e 2005 que consistia numa prova de condução autónoma em que os carros percorriam uma estrada de cerca de 242km no deserto do \emph{Mojave}. Em 2004 nenhum dos concorrentes chegou ao final da prova, sendo que o robô que mais distância percorreu ficou pelos 18km.

Em 2007 foi realizado um \emph{Urban Challenge} onde se aproximou as provas às condições encontradas num ambiente urbano, ou seja, estradas com carros a circular em ambas as vias, cruzamentos, sinalização vertical  e semáforos.

Na edição de 2007 os veículos autónomos já se encontravam equipados com um conjunto de sensores, entre os quais se destacam LIDAR, Radares, sonares e infravermelhos. O projeto vencedor desenvolvido pela Universidade de \emph{Carnegie Mellon} e apelidado de \emph{Boss} \cite{Urmson:2008:ADU:1395073.1395077} possuía 18 sensores dispostos como apresentado no diagrama abaixo:

\begin{center}
	\includegraphics[width=0.80\textwidth]{./figures/boss_sensors.png}
	\captionof{figure}{Sensores no Boss \cite{Urmson:2008:ADU:1395073.1395077}.}
	\label{fig:2}
\end{center}

\begin{table}
\begin{center}
\begin{tabular} { c c l }
	Sigla & Tipo de Equipamento & Modelo \\
	\hline
	APLX & GPS & Applanix POS-LV 220/420 GPS/IMU \\
	LMS & LIDAR & SICK LMS 291-S05/S14 LIDAR \\
	HDL & LIDAR & Velodyne HDL-64 LIDAR \\
	ISF & LIDAR & Continental ISF 172 LIDAR \\
	XT & LIDAR & IBEO Alasca XT LIDAR \\
	ARS & RADAR & Continental ARS 300 Radar \\
	PGF & Câmara HDR & Point Grey Firefly \\
	\hline
\end{tabular}
	\caption{Listagem dos sensores do \emph{Boss}}
	\label{boss_sensor}
\end{center}
\end{table}

Sendo que os códigos dos sensores correspondem ao indicado na tabela ~\ref{boss_sensor} pode-se concluir, que os sensores LIDAR são um excelente sensor para ajudar no reconhecimento de objetos no mundo, tal como para mapear o ambiente do robô para se poder orientar de uma forma eficaz.


\subsection{Micro Rato}

O  Micro Rato é uma competição criada pela Universidade de Aveiro, onde pequenos robôs de tamanho máximo 300x300x400mm têm de navegar num labirinto. A competição é dividida em duas partes, sendo que o objetivo da primeira é que os robôs encontrem um caminho para uma zona onde existe um farol que emite infravermelhos, e na segunda parte fazerem o caminho de volta para a zona de partida utilizando a informação coletada durante a primeira parte da competição.


\subsection{Festival Nacional de Robótica}

O festival nacional de robótica é um evento organizado anualmente pela sociedade
portuguesa de robótica em cidades diferentes onde, além de um encontro de científico
onde investigadores de robótica de todo o mundo discutem e apresentam os trabalhos
que estão a desenvolver, são realizadas várias competições e demonstrações de robótica.

As competições que se realizam são as seguintes:
\begin{itemize}
\item    Busca e Salvamento Júnior RoboCup
\item    Dança Júnior RoboCup
\item    Futebol Robótico Júnior RoboCup
\item    Condução Autónoma
\item    Liga INFAIMON Futebol Robótico Médio RoboCup
\item    FreeBots
\item    Robot@Factory
\item    Equipas
\item    Qualificações para o RoboCup
\end{itemize}

Destas competições, a mais relevante para o trabalho a ser desenvolvido no 
âmbito desta dissertação é a de Competição Autónoma, onde um robô totalmente 
autónomo tem de navegar numa pista em oito que tem as características apresentadas:

\begin{center}
	\includegraphics[width=1.00\textwidth]{./figures/ca_pista.png}
	\captionof{figure}{Pista de Condução Autónoma no Festival Nacional de Robótica}
	\label{fig:3}
\end{center}

O objetivo é o robô percorrer a pista circulando pela faixa da direita, seguindo
as indicações no sinais verticais que se situam à beira da pista e os semáforos,
e evitar os obstáculos que sinalizam obras no percurso.


\subsection{MINERVA}
O minerva é um robô autónomo desenvolvido na universidade Carnegie Mellon, para
fazer de robô guia no museu Smithsonian para a exposição de história natural que esteve em exibição no período de 25 de Agosto a 5 de Setembro de 1998.

\begin{center}
	\includegraphics[width=0.20\textwidth]{./figures/minerva.png}
	\captionof{figure}{MINERVA - Robô guia do museu Smithsonian}
	\label{fig:4}
\end{center}

Este robô tornava-se totalmente autónomo a partir do momento em que fazia uma volta de aprendizagem, em que era guiado pelo percurso que lhe estava destinado. Estando a aprendizagem concluída, o robô orientava-se pelo resultado da sua aprendizagem, e por alguns sensores, nomeadamente para se desviar dos visitantes e de obstáculos, uma câmara para detetar marcadores no teto do museu para se conseguir localizar.
Além de guiar os visitantes pelo percurso este robô também interagia com os mesmos, respondendo a perguntas e apresentando a exposição.

\subsection{CleanRob}

O CleanRob é um projeto que começou a ser desenvolvido na Faculdade de Engenharia da Universidade do Porto em 2004, no no contexto do Departamento de Engenharia Eletrotécnica e de Computadores. Este robô foi desenvolvido por alunos de modo a envolver alunos no desenvolvimento de projetos académicos com maior aplicação prática tirando partido de técnicas que representam o estado da arte na robótica.

Este robô utiliza um conjunto de câmaras e sonares PSD para fazer a sua localização, de modo a limpar corredores do departamento de Engenharia Eletrotécnica.

\begin{center}
	\includegraphics[width=0.40\textwidth]{./figures/clean_rob.jpg}
	\captionof{figure}{CleanRob}
	\label{fig:6}
\end{center}


\section{Resumo}

No que diz respeito a deteção de objetos, existem vários algoritmos bastante robustos e eficazes, contudo são muito voltados para reconhecimento em imagens RGB e não tanto baseados em conjuntos de dados 3D e além disso exigem uma fase de aprendizagem.

Os demonstradores autónomos que existem no momento já são bastante completos, considere-se como exemplo o \emph{Boss} que navega em ambiente bastante próximo do urbano com proeza,
estando cada vez mais próximo de um cenário onde condução autónoma nas cidades poderia ser
uma realidade e até mesmo uma mais-valia em termos de segurança. É de assinalar também os esforços
nas competições de robôs em escalas menores pois com menos recursos e menor escala consegue-se
testar técnicas inovadoras com soluções menos dispendiosas obtendo-se resultados igualmente
impressionantes.

